{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aef7b2e8-99f9-43a1-9f93-75faef49847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import subprocess\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from rioxarray import merge\n",
    "from osgeo import gdal\n",
    "from joblib import Parallel, delayed\n",
    "import sqlite3\n",
    "os.environ['GDAL_NUM_THREADS'] = 'ALL_CPUS' # probably not necessary as does not trigger anything in gdal_translate or gdal2tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ba263279-ad3e-4bec-8041-dfa6e840ca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will process 1069 files from /media/maffe/nvme/iceboost_global_deploy/iceboost_20250212/RGI62/rgi9\n"
     ]
    }
   ],
   "source": [
    "rgi = 9\n",
    "version = '62'\n",
    "MAX_VAL_MAPBOX = 800\n",
    "cmap = plt.get_cmap('turbo', 256)\n",
    "PATH_TIFFS_IN = f\"/media/maffe/nvme/iceboost_global_deploy/iceboost_20250212/RGI{version}/rgi{rgi}\"\n",
    "tif_filenames = [os.path.basename(file) for file in glob.glob(f'{PATH_TIFFS_IN}/*.tif')]\n",
    "output_directory = f\"/media/maffe/nvme/iceboost_global_deploy/iceboost_20250212/RGI{version}/mapbox_rgi{rgi}/\"\n",
    "print(f\"We will process {len(tif_filenames)} files from {PATH_TIFFS_IN}\")\n",
    "n_jobs = 8  # Number of parallel processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7db31d3b-af48-4180-85ac-4e7bf5782a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▌                               | 208/1069 [00:01<00:06, 143.32it/s]/home/maffe/anaconda3/envs/skynetenv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████| 1069/1069 [00:08<00:00, 125.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have no. tif to process: 1069\n"
     ]
    }
   ],
   "source": [
    "# Process individual TIF files and save them as .tif in the temporary /tmp folder (we will remove them in the end)\n",
    "\n",
    "def process_tif(tif_name, path_tiffs_in, cmap, max_val_mapbox):\n",
    "    \"\"\"Function to process a single tif file.\"\"\"\n",
    "    tif = rioxarray.open_rasterio(f\"{path_tiffs_in}/{tif_name}\").sel(band=1)  # EPSG:4326\n",
    "    tif = tif.squeeze().rio.reproject(dst_crs=\"EPSG:3857\").clip(0, max_val_mapbox).fillna(0)\n",
    "    \n",
    "    rgba_data = cmap(tif.values / max_val_mapbox) * 255\n",
    "    #rgba_data[:, :, 3] = 127  # Set alpha to half transparency\n",
    "    #rgba_data[tif.values == 0] = 0\n",
    "    \n",
    "    # Set alpha to fully transparent (0) where data is bad (0)\n",
    "    rgba_data[tif.values == 0] = [0, 0, 0, 0]  # Fully transparent for bad data\n",
    "    \n",
    "    rgba_data = rgba_data.astype(np.uint8)\n",
    "    \n",
    "    rgb_data_array = xr.DataArray(\n",
    "        rgba_data, dims=('y', 'x', 'band'),\n",
    "        coords={'x': tif.coords['x'], 'y': tif.coords['y']}\n",
    "    ).transpose('band', 'y', 'x')\n",
    "    \n",
    "    rgb_data_array.rio.write_crs(\"EPSG:3857\", inplace=True)\n",
    "    rgb_data_array.rio.write_nodata(0, inplace=True)\n",
    "    \n",
    "    # Skip 1-pixel glaciers\n",
    "    if rgb_data_array.shape[1] == 1 or rgb_data_array.shape[2] == 1:\n",
    "        return None\n",
    "    \n",
    "    # Save to a temporary file and return its path\n",
    "    temp_file = tempfile.NamedTemporaryFile(suffix=\".tif\", delete=False).name\n",
    "    rgb_data_array.rio.to_raster(temp_file, compress=\"deflate\")\n",
    "    return temp_file\n",
    "\n",
    "# Parallel processing\n",
    "processed_tifs = Parallel(n_jobs=n_jobs)(\n",
    "    delayed(process_tif)(tif_name, PATH_TIFFS_IN, cmap, MAX_VAL_MAPBOX) \n",
    "    for tif_name in tqdm(tif_filenames, total=len(tif_filenames))\n",
    ")\n",
    "\n",
    "# Remove None values (from skipped 1-pixel glaciers)\n",
    "processed_tifs = [tif for tif in processed_tifs if tif is not None]\n",
    "print(f\"We have no. tif to process: {len(processed_tifs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e1a63e63-6d3f-443e-834c-9813d6000db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin VRT creation\n",
      "temp.vrt successfully created.\n",
      "Size of temp.vrt: 1935.42 KB\n",
      "End VRT creation in 0.89 sec\n",
      "Begin MBTiles generation\n",
      "Input file size is 84301, 52594\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "MBTiles file created at: rgi9.mbtiles in 113.04 sec\n",
      "Updating minzoom and maxzoom in MBTiles metadata...\n",
      "Updated minzoom to 3 and maxzoom to 10 in metadata.\n",
      "Deleted temp.vrt.\n"
     ]
    }
   ],
   "source": [
    "vrt_path = \"temp.vrt\"  # Temporary VRT file\n",
    "geojson_output = f\"rgi{rgi}.geojson\"\n",
    "mbtiles_output = f\"rgi{rgi}.mbtiles\"  # Output MBTiles file\n",
    "\n",
    "try:\n",
    "    # Step 1: Create a Virtual Raster (VRT)\n",
    "    print(f'Begin VRT creation')\n",
    "    t1_0 = time.time()\n",
    "    gdal.BuildVRT(vrt_path, processed_tifs)\n",
    "    if os.path.exists(vrt_path):\n",
    "        print(f\"{vrt_path} successfully created.\")\n",
    "        vrt_size = os.path.getsize(vrt_path)\n",
    "        print(f\"Size of {vrt_path}: {vrt_size / 1024:.2f} KB\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Failed to create {vrt_path}.\")\n",
    "    print(f\"End VRT creation in {time.time()-t1_0:.2f} sec\")\n",
    "    \n",
    "    # Step 2: Convert VRT to MBTiles using gdal_translate\n",
    "    translate_command = [\n",
    "        'gdal_translate',\n",
    "        '-mask', '4',\n",
    "        '-of', 'MBTILES',  # Output format MBTiles\n",
    "        '-co', 'TILE_FORMAT=PNG',  # Tile format (PNG or JPEG)\n",
    "        '-co', 'ZOOM_LEVEL_STRATEGY=LOWER',  # The nearest lower zoom level (less detailed) is chosen.\n",
    "        vrt_path, mbtiles_output\n",
    "    ]\n",
    "\n",
    "    print(f'Begin MBTiles generation')\n",
    "    t2_0 = time.time()\n",
    "    subprocess.run(translate_command, check=True)\n",
    "    subprocess.run(['gdaladdo', '-r', 'bilinear', mbtiles_output, '2', '4', '8', '16', '32', '64', '128'], check=True)\n",
    "    print(f\"MBTiles file created at: {mbtiles_output} in {time.time()-t2_0:.2f} sec\")\n",
    "\n",
    "    # Step 3: Update minzoom and maxzoom in Metadata\n",
    "    print(\"Updating minzoom and maxzoom in MBTiles metadata...\")\n",
    "    min_zoom = 3  # Set your desired minimum zoom level\n",
    "    max_zoom = 10  # Set your desired maximum zoom level\n",
    "    conn = sqlite3.connect(mbtiles_output)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"UPDATE metadata SET value = ? WHERE name = 'minzoom';\", (min_zoom,))\n",
    "    cursor.execute(\"UPDATE metadata SET value = ? WHERE name = 'maxzoom';\", (max_zoom,))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Updated minzoom to {min_zoom} and maxzoom to {max_zoom} in metadata.\")\n",
    "\n",
    "finally:\n",
    "    # Cleanup temporary files\n",
    "    for file_path in [vrt_path]:\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted {file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d41a1f21-6fbd-4e49-b347-d7646c26bce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 1069 .tif files, freeing 112.51 MB.\n"
     ]
    }
   ],
   "source": [
    "# If something is left in /tmp remove any .tif file (it should not be necessary)\n",
    "\n",
    "# Find all .tif files in /tmp\n",
    "junk_tif_files = glob.glob(\"/tmp/*.tif\")\n",
    "\n",
    "# Calculate total size of the .tif files\n",
    "total_size_mb = sum(os.path.getsize(f) for f in junk_tif_files if os.path.isfile(f)) / (1024 ** 2)\n",
    "num_files = len(junk_tif_files)\n",
    "\n",
    "# Delete each file\n",
    "for file_path in junk_tif_files:\n",
    "    os.remove(file_path)\n",
    "    #print(f\"Deleted {file_path}\")\n",
    "\n",
    "print(f\"Deleted {num_files} .tif files, freeing {total_size_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38655c-06d1-4e83-8c66-f723e7bd5b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
